{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1nQAfLYMSRPThffIZJSnDNLpM0pcv7Vuc","timestamp":1729644245563}],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# PyTorch 기초\n"],"metadata":{"id":"CGhTHTMNh8tG"}},{"cell_type":"markdown","source":["## 1. PyTorch 소개\n","\n","PyTorch는 딥러닝(Deep Learning)을 위한 Python 오픈소스 라이브러리로, Meta에서 개발되었습니다. PyTorch는 유연하고 효율적이며 사용이 쉬운 설계로 많은 연구자와 개발자들이 애용하고 있습니다."],"metadata":{"id":"cT4LnUkXiAWA"}},{"cell_type":"markdown","source":["### 주요 특징\n","\n","- 동적 계산 그래프\n","\n","    PyTorch는 동적 계산 그래프를 지원합니다. 이를 통해 실행 중에도 그래프 구조를 자유롭게 변경할 수 있어, 복잡한 모델 아키텍처를 쉽게 구현할 수 있습니다. 이 유연성 덕분에 실험과 연구 환경에서 매우 강력한 도구로 사용됩니다.\n","\n","- GPU 가속\n","\n","    GPU를 통해 연산 속도를 대폭 향상시킬 수 있습니다. 특히, 대규모 데이터셋을 다루거나 복잡한 모델을 훈련할 때 GPU 활용은 필수적입니다.\n","\n","- 간단하고 직관적인 인터페이스 제공\n","\n","    Python 특유의 직관성과 디버깅 용이성을 살려, 간단하고 유연한 코드 작성을 지원합니다. 사용자 친화적인 API 덕분에 연구부터 상용 개발까지 폭넓게 사용됩니다.\n","\n","- 활발한 커뮤니티\n","\n","    PyTorch는 HuggingFace와 같은 커뮤니티에서 활발하게 지원되고 있습니다. 방대한 라이브러리와 도구들이 공유되며, 문제 해결에 대한 지원도 빠르고 다양합니다."],"metadata":{"id":"DZAIEnhFAb-O"}},{"cell_type":"markdown","source":["그렇다면, 이제 PyTorch를 import하고 버전을 확인해보겠습니다."],"metadata":{"id":"09x1jfTJG9CS"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1AXSdajW8os","executionInfo":{"status":"ok","timestamp":1729612440806,"user_tz":-540,"elapsed":8533,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"0ffb7715-d59e-4d01-e4e4-029411d989c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch Version: 2.4.1+cu121\n"]}],"source":["import torch\n","\n","# PyTorch 버전 확인\n","print(f\"PyTorch Version: {torch.__version__}\")"]},{"cell_type":"markdown","source":["그리고, GPU 가속 활용 여부에 대해서도 확인해보도록 하겠습니다."],"metadata":{"id":"3sqhXreLDC6Z"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2L0U3u4Qu2ak","executionInfo":{"status":"ok","timestamp":1729612440806,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"779fa6ba-f212-4540-84e2-fde6e74bfd86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Oct 22 15:54:00 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# CUDA 사용 가능 여부 확인\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","\n","# MPS 사용 가능 여부 확인 (Mac GPU)\n","if torch.backends.mps.is_available():\n","    print(\"MPS available: True\")\n","else:\n","    print(\"MPS available: False\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrryjoPLDCN5","executionInfo":{"status":"ok","timestamp":1729612440806,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"dbebc601-6d2a-4e98-8426-69d47034b60e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n","MPS available: False\n"]}]},{"cell_type":"markdown","source":["만약 CUDA / GPU를 사용해야 하는 상황이라면 런타임에서 런타임 유형을 변경해주시면 됩니다.\n","\n","Google Colab에서 GPU를 사용하려면 다음 단계를 따라주세요:\n","1. 메뉴에서 \"런타임\" > \"런타임 유형 변경\"을 선택합니다.\n","2. 하드웨어 가속기 옵션에서 \"GPU\"를 선택한 후 \"저장\"을 클릭합니다.\n","\n","Mac 사용자의 경우, MPS 지원이 활성화된 경우 자동으로 Mac GPU를 사용할 수 있습니다."],"metadata":{"id":"jT7kYy7nRrey"}},{"cell_type":"markdown","source":["## 2. PyTorch 기초 텐서\n","\n","PyTorch는 딥러닝 프레임워크 중 하나로, 데이터를 처리하는 데 텐서(Tensor)라는 자료 구조를 사용합니다.\n","\n","텐서는 NumPy `ndarray` 과 비슷하지만, GPU를 사용하여 빠른 계산을 할 수 있다는 차이점이 있습니다.\n","\n","PyTorch에서 텐서는 데이터를 표현하는 기본 도구이며, 수학적 연산, 딥러닝 모델의 가중치 등을 계산할 때 사용됩니다."],"metadata":{"id":"dMPQCtIriFrp"}},{"cell_type":"markdown","source":["### 텐서의 차원 이해하기\n","\n","텐서는 차원(Rank)에 따라 여러 가지로 나뉩니다.\n","\n","차원에 따라 다음과 같은 형태로 구분됩니다.\n","\n","1. 스칼라 (Scalar): 하나의 숫자입니다. 차원이 없는 0차원 텐서입니다.\n","\n","2. 벡터 (Vector): 숫자가 나열된 리스트처럼 생긴 1차원 텐서입니다.\n","\n","3. 행렬 (Matrix): 숫자들이 2차원 평면에 배치된 표처럼 생긴 2차원 텐서입니다.\n","\n","4. 배열 (Array): 여러 개의 행렬이 쌓여 있는 3차원 이상의 텐서입니다. 이미지를 표현할 때 주로 사용됩니다."],"metadata":{"id":"Z6Fkyb8pmiUd"}},{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","\n","# 1. 스칼라 (0차원 텐서)\n","scalar_tensor = torch.tensor(5)\n","\n","# 2. 벡터 (1차원 텐서)\n","vector_tensor = torch.tensor([1, 2, 3])\n","\n","# 3. 행렬 (2차원 텐서)\n","matrix_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","\n","# 4. 배열 (3차원 텐서) - RGB 이미지를 표현할 때 사용\n","array_tensor = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n","\n","# 텐서 출력\n","print(\"Scalar:\", scalar_tensor)\n","print(\"Vector:\", vector_tensor)\n","print(\"Matrix:\\n\", matrix_tensor)\n","print(\"Array:\\n\", array_tensor)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDZgKiGdmpwh","executionInfo":{"status":"ok","timestamp":1729612441472,"user_tz":-540,"elapsed":669,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"569bb3ba-c7a2-4e37-bd29-c0b88e504081"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scalar: tensor(5)\n","Vector: tensor([1, 2, 3])\n","Matrix:\n"," tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","Array:\n"," tensor([[[ 1,  2],\n","         [ 3,  4]],\n","\n","        [[ 5,  6],\n","         [ 7,  8]],\n","\n","        [[ 9, 10],\n","         [11, 12]]])\n"]}]},{"cell_type":"markdown","source":["<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--8pw60d5S--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0201a.png\">"],"metadata":{"id":"vQk-Y3IznPUx"}},{"cell_type":"markdown","source":["### 2.1 텐서 생성\n","\n","PyTorch에서 텐서를 생성하는 방법은 NumPy에서 배열을 생성하는 방법과 매우 유사합니다.\n","\n","텐서는 PyTorch의 기본 데이터 구조로, 숫자, 벡터, 행렬, 또는 더 높은 차원의 배열을 나타냅니다.\n","\n","텐서를 생성하는 가장 일반적인 방법은 torch.tensor() 함수를 사용하는 것입니다.\n","\n","예를 들어, 다음 코드는 1차원 텐서를 생성하는 방법을 보여줍니다."],"metadata":{"id":"K-AFNWIc0vi5"}},{"cell_type":"code","source":["# 1차원 텐서 생성\n","x = torch.tensor([1, 2, 3])\n","print(f\"1D Tensor: {x}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z45jwbcQiaSM","executionInfo":{"status":"ok","timestamp":1729612441472,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"dd67b4ad-ceec-43c9-949e-0ac626726291"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1D Tensor: tensor([1, 2, 3])\n"]}]},{"cell_type":"markdown","source":["- torch.tensor(): 주어진 데이터로 텐서를 생성합니다."],"metadata":{"id":"3AM0Hr2UqCcx"}},{"cell_type":"markdown","source":["### 2.2 텐서 속성\n","\n","텐서는 여러 속성을 가지고 있으며, 그 중 가장 중요한 속성은 다음과 같습니다.\n","\n","1. 형태(Shape)\n","\n","    텐서의 차원과 크기를 나타냅니다. 이는 텐서가 몇 차원으로 이루어졌는지를 알려줍니다.\n","\n","2. 자료형(dtype)\n","\n","    텐서에 저장된 데이터의 유형을 의미합니다. 예를 들어, 정수, 실수 등이 있습니다.\n","\n","3. 장치(device)\n","\n","    텐서가 CPU에서 연산되는지, GPU에서 연산되는지를 나타냅니다. PyTorch는 GPU 가속을 지원하므로, GPU를 사용하고 싶을 때는 장치를 cuda로 설정할 수 있습니다."],"metadata":{"id":"mbekRhGLoWm5"}},{"cell_type":"code","source":["# 텐서의 데이터 타입과 형태 확인\n","print(f\"1D Tensor's data type: {x.dtype}\")\n","print(f\"1D Tensor's shape: {x.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNKY8lUAPjpU","executionInfo":{"status":"ok","timestamp":1729612441472,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"4c290bcf-c5c6-450d-f868-40036e01148c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1D Tensor's data type: torch.int64\n","1D Tensor's shape: torch.Size([3])\n"]}]},{"cell_type":"markdown","source":["- dtype: 텐서의 데이터 타입을 나타냅니다 (예: int64, float32).\n","- shape: 텐서의 차원과 크기를 확인할 수 있습니다."],"metadata":{"id":"zOgQ3zuqP24q"}},{"cell_type":"code","source":["# 만약 텐서 안에 하나라도 실수가 포함되면?\n","y = torch.tensor([1, 2, 3.14, 4])\n","print(y)\n","print(f\"y Tensor's data type: {y.dtype}\")  # dtype이 float로 처리됨\n","print(f\"y Tensor's shape: {y.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdhyJZtrivOB","executionInfo":{"status":"ok","timestamp":1729612441472,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"68994317-a4e9-4f0b-a538-22b39febbc89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.0000, 2.0000, 3.1400, 4.0000])\n","y Tensor's data type: torch.float32\n","y Tensor's shape: torch.Size([4])\n"]}]},{"cell_type":"code","source":["# 2차원 텐서 생성\n","z = torch.tensor([[1, 2], [3, 4]])\n","print(f\"\\n2D Tensor:\\n{z}\")\n","print(f\"2D Tensor's data type: {z.dtype}\")\n","print(f\"2D Tensor's shape: {z.shape}\")\n","print(f\"2D Tensor's dimension: {z.ndim}\")  # 텐서의 차원 수\n","print(f\"2D Tensor's total number of elements: {z.numel()}\")  # 총 원소 개수\n","print(f\"2D Tensor's device: {z.device}\")  # 텐서가 어느 device에서 연산 중인지 확인"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3K4t5ZjJjDDf","executionInfo":{"status":"ok","timestamp":1729612441472,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"daed0631-be7f-452f-b931-9d7eb63c985e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","2D Tensor:\n","tensor([[1, 2],\n","        [3, 4]])\n","2D Tensor's data type: torch.int64\n","2D Tensor's shape: torch.Size([2, 2])\n","2D Tensor's dimension: 2\n","2D Tensor's total number of elements: 4\n","2D Tensor's device: cpu\n"]}]},{"cell_type":"markdown","source":["- numel(): 텐서의 총 원소 개수를 반환합니다.\n","- device: 텐서가 CPU에서 연산 중인지, GPU에서 연산 중인지 알려줍니다."],"metadata":{"id":"ako6gN1vp3YL"}},{"cell_type":"code","source":["# 2차원 텐서에서 주의할 사항!\n","a = torch.tensor([[1, 2, 3], [4, 5]])  # 첫 번째 행은 3개, 두 번째 행은 2개\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"id":"4GZSOtWJUIS-","executionInfo":{"status":"error","timestamp":1729612441472,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"d596ef0b-49b2-445e-e0b1-db8d13e694e7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"expected sequence of length 3 at dim 1 (got 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-490c9195b66c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2차원 텐서에서 주의할 사항!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 첫 번째 행은 3개, 두 번째 행은 2개\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"]}]},{"cell_type":"markdown","source":["1. 오류 발생 원인:\n","\n","    - PyTorch에서 2차원 텐서를 생성할 때는 모든 행의 길이가 같아야 합니다. 즉, 텐서가 행렬 형태를 유지하려면 각 행에 동일한 개수의 요소가 있어야 합니다.\n","\n","    - 하지만, 위의 코드에서는 torch.tensor([[1, 2, 3], [4, 5]])와 같이 첫 번째 행은 3개의 요소를 가지고, 두 번째 행은 2개의 요소를 가지도록 텐서를 생성하려고 했습니다. 이처럼 행의 길이가 다르기 때문에 PyTorch는 텐서를 생성할 수 없고, ValueError를 발생시킵니다.\n","\n","2. 오류 메시지 해석:\n","\n","    오류 메시지 ValueError: expected sequence of length 3 at dim 1 (got 2)는 다음과 같은 의미를 갖습니다.\n","\n","    - expected sequence of length 3 at dim 1: 1차원(dim 1)에서 길이가 3인 시퀀스를 기대했습니다. 즉, 각 행의 길이가 3이어야 합니다.\n","    \n","    - (got 2): 하지만 길이가 2인 시퀀스를 받았습니다.\n","\n","    - 오류를 해결하려면 모든 행의 길이를 동일하게 맞추거나, 불규칙한 길이의 데이터를 다루기 위해서는 리스트 대신 다른 방법 (예: 패딩, 가변 길이 텐서)을 고려해야 합니다."],"metadata":{"id":"9-VJEzFHVGHd"}},{"cell_type":"markdown","source":["### 2.3 텐서 차원 변환\n","\n","텐서의 차원 변환은 딥러닝과 머신러닝에서 자주 사용되는 기능 중 하나로, 모델의 입출력 형태를 맞추거나 특정 연산을 하기 전에 데이터를 적절하게 변환하는 데 유용합니다.\n","\n","PyTorch에서는 reshape() 함수를 사용하여 텐서의 차원을 쉽게 변환할 수 있습니다. 이 함수는 NumPy의 reshape() 함수와 동일한 방식으로 동작합니다.\n","\n"],"metadata":{"id":"Sw4UmykSqivP"}},{"cell_type":"code","source":["# 랜덤 텐서 생성 (기본적으로 1차원 텐서로 생성)\n","tensor = torch.rand(2, 3)\n","print(\"Original Tensor:\")\n","print(tensor)\n","print(\"Original Tensor Shape:\", tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDPFJB07qvwe","executionInfo":{"status":"ok","timestamp":1729612444800,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"7394831f-b38c-4395-d996-346d67aad386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Tensor:\n","tensor([[0.6715, 0.7615, 0.5328],\n","        [0.2472, 0.8774, 0.6597]])\n","Original Tensor Shape: torch.Size([2, 3])\n"]}]},{"cell_type":"markdown","source":["- torch.rand(): 0과 1 사이의 무작위 숫자를 균등 분포로 생성하는 함수 (0 이상 1 미만의 범위를 갖음.)\n","\n","- torch.rand(2, 3): 무작위 값으로 채워진 2x3 텐서를 생성합니다."],"metadata":{"id":"ia1dCjLmrkSZ"}},{"cell_type":"code","source":["# 텐서의 차원 변환 (2x3 텐서를 3x2 텐서로 변환)\n","tensor_reshaped = tensor.reshape(3, 2)\n","print(\"\\nReshaped Tensor (3x2):\")\n","print(tensor_reshaped)\n","print(\"Reshaped Tensor Shape:\", tensor_reshaped.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-CnxA1BrgSB","executionInfo":{"status":"ok","timestamp":1729612444800,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"e16744ec-dc66-4aa8-dedc-402e06c4e78f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Reshaped Tensor (3x2):\n","tensor([[0.6715, 0.7615],\n","        [0.5328, 0.2472],\n","        [0.8774, 0.6597]])\n","Reshaped Tensor Shape: torch.Size([3, 2])\n"]}]},{"cell_type":"markdown","source":["- reshape(3, 2): 2x3 텐서를 3x2 텐서로 변환합니다. 이때 원소의 개수는 그대로 유지해야 합니다."],"metadata":{"id":"JCgRmkaMr-ig"}},{"cell_type":"code","source":["# 2차원에서 1차원으로 변환\n","tensor_flatten = tensor.reshape(-1)\n","print(\"\\nFlattened Tensor:\")\n","print(tensor_flatten)\n","print(\"Flattened Tensor Shape:\", tensor_flatten.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQA8EI19ri9F","executionInfo":{"status":"ok","timestamp":1729612444800,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"d7e0d18b-3e80-43a7-90a4-6c78dcb8b6e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Flattened Tensor:\n","tensor([0.6715, 0.7615, 0.5328, 0.2472, 0.8774, 0.6597])\n","Flattened Tensor Shape: torch.Size([6])\n"]}]},{"cell_type":"markdown","source":["- reshape(-1): 텐서를 1차원으로 변환할 때 사용됩니다. `-1`은 자동으로 차원을 계산하여 텐서를 평탄화(flatten)합니다."],"metadata":{"id":"ArxJtEkIsBvd"}},{"cell_type":"markdown","source":["### 2.4 자료형 설정\n","\n","텐서의 자료형 설정은 딥러닝 모델을 구현할 때 중요한 요소 중 하나입니다.\n","\n","텐서에 저장된 데이터의 형식은 모델의 성능과 메모리 사용량에 영향을 줄 수 있기 때문에 적절한 자료형을 설정하는 것이 매우 중요합니다.\n","\n","PyTorch에서 텐서의 자료형을 설정하는 방식은 NumPy와 유사하지만, PyTorch는 torch.* 형태로 자료형을 명시하는 것이 일반적입니다."],"metadata":{"id":"nuMaHQDOsYMN"}},{"cell_type":"code","source":["# 32비트 부동 소수점(float32)으로 텐서 생성\n","tensor = torch.rand((3, 3), dtype=torch.float)\n","print(\"32-bit float tensor:\")\n","print(tensor)\n","print(\"Data type:\", tensor.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhfgvli0s68l","executionInfo":{"status":"ok","timestamp":1729612444800,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"762c7bff-e9bd-4c9e-a2d7-80a5f6411655"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32-bit float tensor:\n","tensor([[0.8140, 0.5680, 0.1470],\n","        [0.7944, 0.2709, 0.7248],\n","        [0.9671, 0.6012, 0.1801]])\n","Data type: torch.float32\n"]}]},{"cell_type":"markdown","source":["- torch.float (float32): 32비트 부동 소수점 자료형입니다. 딥러닝 모델에서 많이 사용되며, 메모리 사용량이 상대적으로 적고 학습 성능도 적당합니다."],"metadata":{"id":"KlHCPPkxtx-d"}},{"cell_type":"code","source":["# 64비트 부동 소수점(float64)으로 텐서 생성\n","tensor = torch.rand((3, 3), dtype=torch.float64)\n","print(\"\\n64-bit float tensor:\")\n","print(tensor)\n","print(\"Data type:\", tensor.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgXj20XTtSON","executionInfo":{"status":"ok","timestamp":1729612444800,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"6678490b-0de8-4de2-9c7d-37f995f21333"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","64-bit float tensor:\n","tensor([[0.0554, 0.9650, 0.2862],\n","        [0.7361, 0.6032, 0.0057],\n","        [0.3545, 0.9099, 0.0553]], dtype=torch.float64)\n","Data type: torch.float64\n"]}]},{"cell_type":"markdown","source":["- torch.float64: 64비트 부동 소수점 자료형으로, 더 큰 범위의 숫자를 표현할 수 있습니다. 하지만 더 많은 메모리를 사용하며, 일반적으로 32비트보다 연산 속도가 느릴 수 있습니다."],"metadata":{"id":"BodRIvfSt1C5"}},{"cell_type":"markdown","source":["속도와 자원 사용: 부동 소수점 자료형이 커질수록(예: float64), 연산의 정확도는 높아질 수 있지만, 연산 속도는 느려질 수 있으며 더 많은 자원이 필요합니다.\n","\n","따라서, 딥러닝 모델을 구축할 때는 대부분 torch.float과 같은 32비트 부동 소수점을 사용하는 것이 일반적입니다. 데이터의 크기와 요구되는 정확도에 따라 적절한 자료형을 선택하는 것이 중요합니다."],"metadata":{"id":"j7bF5lWQtesd"}},{"cell_type":"code","source":["# 텐서의 자료형 변환\n","tensor = torch.rand((3, 3))\n","print(\"Original tensor data type:\", tensor.dtype)\n","\n","# float32에서 float64로 변환\n","tensor = tensor.to(torch.float64)\n","print(\"Converted tensor data type:\", tensor.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bo-qwLR-t-_B","executionInfo":{"status":"ok","timestamp":1729612444800,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"16c88fc9-3a4c-4035-cf4a-bced74aa102a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original tensor data type: torch.float32\n","Converted tensor data type: torch.float64\n"]}]},{"cell_type":"markdown","source":["이와 같이 to() 메서드를 사용하여 텐서의 자료형을 변환할 수도 있습니다."],"metadata":{"id":"Oo2QdLDyuCDF"}},{"cell_type":"markdown","source":["### 2.5 장치 설정\n","\n","장치 설정은 PyTorch에서 GPU를 활용하여 모델을 학습하는 데 필수적인 설정입니다.\n","\n","장치 설정을 제대로 하지 않으면 GPU를 활용하지 못하고 CPU에서 연산을 진행하게 되어 학습 속도가 크게 느려집니다.\n","\n","따라서 모델 학습을 하기 전에 장치 설정을 반드시 확인해야 합니다."],"metadata":{"id":"CV5CYMO0uEBd"}},{"cell_type":"markdown","source":["#### 1. 장치 설정 기본 예제"],"metadata":{"id":"6kb47vhu7nhT"}},{"cell_type":"code","source":["# CUDA 또는 CPU 장치 설정\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# CPU와 GPU에 각각 텐서 생성\n","cpu_tensor = torch.FloatTensor([1, 2, 3])\n","gpu_tensor = torch.cuda.FloatTensor([1, 2, 3]) if torch.cuda.is_available() else cpu_tensor\n","\n","# 설정한 장치에 텐서 생성\n","tensor = torch.tensor([1, 2, 3], device=device)\n","\n","# 출력\n","print(f\"Device in use: {device}\")\n","print(f\"CPU Tensor: {cpu_tensor}\")\n","print(f\"GPU Tensor: {gpu_tensor}\")\n","print(f\"Tensor on {device}: {tensor}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEKnt79suTpN","executionInfo":{"status":"ok","timestamp":1729612446546,"user_tz":-540,"elapsed":1749,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"d9fea4f1-60dc-40f9-9e7a-f2312f8e8e3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-98949356e539>:6: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n","  gpu_tensor = torch.cuda.FloatTensor([1, 2, 3]) if torch.cuda.is_available() else cpu_tensor\n"]},{"output_type":"stream","name":"stdout","text":["Device in use: cuda\n","CPU Tensor: tensor([1., 2., 3.])\n","GPU Tensor: tensor([1., 2., 3.], device='cuda:0')\n","Tensor on cuda: tensor([1, 2, 3], device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["장치 확인\n","\n","- torch.cuda.is_available()를 사용하여 CUDA 사용 가능 여부를 확인하고, 가능하다면 'cuda'를, 그렇지 않으면 'cpu'를 선택합니다.\n","\n","텐서 생성\n","\n","- device 매개변수를 통해 텐서를 원하는 장치에 할당합니다. 장치 간의 통일된 설정을 통해 모델 코드 전체에서 통일된 장치를 사용할 수 있습니다."],"metadata":{"id":"5OYy2JbdvL4E"}},{"cell_type":"markdown","source":["#### 2. 애플 실리콘 (M1/M2/M3)에서 MPS 설정\n","\n","애플 실리콘을 사용하는 경우 CUDA 대신 **MPS (Metal Performance Shaders)**를 이용하여 GPU 가속을 할 수 있습니다. 이 경우, MPS 가속을 확인하고 장치를 설정할 수 있습니다."],"metadata":{"id":"3jeC8Boa7q3H"}},{"cell_type":"code","source":["# MPS 또는 CPU 장치 설정 (Apple Silicon)\n","device = \"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cpu\"\n","\n","# 설정한 장치에 텐서 생성\n","tensor = torch.tensor([1, 2, 3], device=device)\n","\n","# 출력\n","print(f\"Device in use: {device}\")\n","print(f\"Tensor on {device}: {tensor}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVR35QTQ7rx8","executionInfo":{"status":"ok","timestamp":1729612446546,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"c085e637-0394-4d14-9994-4052af3a0e7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device in use: cpu\n","Tensor on cpu: tensor([1, 2, 3])\n"]}]},{"cell_type":"markdown","source":["- MPS 사용 확인: torch.backends.mps.is_available()와 torch.backends.mps.is_built()를 사용하여 MPS 사용 가능 여부를 확인합니다.\n","- 장치 설정: MPS가 가능하다면 'mps'를, 그렇지 않으면 'cpu'를 사용합니다."],"metadata":{"id":"sWCl6ZOH7s9L"}},{"cell_type":"markdown","source":["### 2.6 장치 변환\n","\n","PyTorch에서는 텐서를 CPU와 GPU 간에 쉽게 변환할 수 있습니다. 다만, CPU에서 사용하는 텐서와 GPU에서 사용하는 텐서는 직접적인 연산이 불가능합니다. 따라서, 연산을 수행하기 전에 필요한 장치로 텐서를 변환해야 합니다.\n","\n","또한, NumPy 배열을 PyTorch 텐서로 변환하거나, PyTorch 텐서를 다시 NumPy 배열로 변환하는 것도 가능합니다. 이 기능을 통해 NumPy와 PyTorch 간에 데이터를 쉽게 주고받을 수 있습니다."],"metadata":{"id":"VM5MmP-8vQRw"}},{"cell_type":"markdown","source":["장치 변환 예제\n","\n","1. CPU 텐서를 GPU로 변환 (cuda(), to(\"cuda\"))\n","2. GPU 텐서를 CPU로 변환 (cpu())\n","3. NumPy 배열을 텐서로 변환, 텐서를 NumPy 배열로 변환"],"metadata":{"id":"70t4M1bNwfSc"}},{"cell_type":"markdown","source":["#### 장치 간 상호 변환\n","\n","- cuda(): CPU 장치에 있는 텐서를 GPU로 변환합니다.\n","- cpu(): GPU 장치에 있는 텐서를 다시 CPU로 변환합니다.\n","- to() 메서드를 사용하여 다양한 장치 간에 텐서를 변환할 수 있습니다. 특히, 애플 실리콘이 탑재된 Mac에서는 cuda() 대신 to(\"mps\")를 사용하여 GPU(MPS)로 변환할 수 있습니다."],"metadata":{"id":"R0xqNb8Zw6he"}},{"cell_type":"code","source":["# 1. CPU 텐서를 GPU로 변환\n","cpu_tensor = torch.FloatTensor([1, 2, 3])\n","print(\"CPU Tensor:\", cpu_tensor)\n","\n","if torch.cuda.is_available():\n","    gpu_tensor = cpu_tensor.cuda()  # CPU -> GPU 변환\n","    print(\"GPU Tensor:\", gpu_tensor)\n","\n","    gpu_to_cpu_tensor = gpu_tensor.cpu()  # 다시 GPU -> CPU 변환\n","    print(\"GPU to CPU Tensor:\", gpu_to_cpu_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYDoN60ovcWz","executionInfo":{"status":"ok","timestamp":1729612446546,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"7483d757-8a9a-4695-a38c-fc2292a6412e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU Tensor: tensor([1., 2., 3.])\n","GPU Tensor: tensor([1., 2., 3.], device='cuda:0')\n","GPU to CPU Tensor: tensor([1., 2., 3.])\n"]}]},{"cell_type":"markdown","source":["- CPU 텐서를 GPU로 변환\n","\n","    - cpu_tensor.cuda() 또는 cpu_tensor.to(\"cuda\")를 사용하여 CPU에서 GPU로 텐서를 변환할 수 있습니다. 이 기능은 CUDA가 활성화된 경우에만 가능합니다.\n","\n","- GPU 텐서를 CPU로 변환:\n","\n","    - gpu_tensor.cpu()를 사용하여 GPU에서 CPU로 텐서를 다시 변환할 수 있습니다."],"metadata":{"id":"C1roWK-TxIXg"}},{"cell_type":"code","source":["# 2. to() 메서드를 사용한 장치 변환 (Apple Silicon M1/M2/M3의 경우 MPS로 변환)\n","if torch.backends.mps.is_available():\n","    mps_tensor = cpu_tensor.to(\"mps\")  # CPU -> MPS 변환 (Apple Silicon)\n","    print(\"MPS Tensor (Apple Silicon):\", mps_tensor)\n","    mps_to_cpu_tensor = mps_tensor.cpu()  # MPS -> CPU 변환\n","    print(\"MPS to CPU Tensor:\", mps_to_cpu_tensor)"],"metadata":{"id":"pHOs-yaKvrKV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Apple Silicon(M1/M2/M3)에서 MPS 장치 사용\n","\n","    - cpu_tensor.to(\"mps\")를 사용하여 Apple Silicon에서는 MPS 장치로 텐서를 변환할 수 있습니다."],"metadata":{"id":"RiGbMkhFxL4s"}},{"cell_type":"code","source":["# 3. NumPy 배열과 PyTorch 텐서 간 변환\n","import numpy as np\n","\n","numpy_array = np.array([1, 2, 3])  # NumPy 배열\n","tensor_from_numpy = torch.from_numpy(numpy_array)  # NumPy -> PyTorch 텐서\n","print(\"\\nNumPy to Tensor:\", tensor_from_numpy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpMP0pRSxFZv","executionInfo":{"status":"ok","timestamp":1729612446546,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"0f39270b-99db-47b1-ee3d-97291e38a1f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","NumPy to Tensor: tensor([1, 2, 3])\n"]}]},{"cell_type":"markdown","source":["- torch.from_numpy()를 사용하여 NumPy 배열을 PyTorch 텐서로 변환할 수 있습니다.\n"],"metadata":{"id":"hjqAIbjHxZvd"}},{"cell_type":"code","source":["# 텐서를 NumPy 배열로 변환\n","tensor = torch.tensor([4, 5, 6])\n","numpy_from_tensor = tensor.numpy()  # PyTorch 텐서 -> NumPy 배열\n","print(\"Tensor to NumPy:\", numpy_from_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d086UvwvxG4W","executionInfo":{"status":"ok","timestamp":1729612446546,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"118e31dc-e313-4d5a-9a32-50ed10fa07f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor to NumPy: [4 5 6]\n"]}]},{"cell_type":"markdown","source":["- tensor.numpy()를 사용하여 PyTorch 텐서를 NumPy 배열로 변환할 수 있습니다. 단, GPU 텐서는 바로 변환할 수 없으며, 먼저 CPU로 변환한 후에 변환해야 합니다."],"metadata":{"id":"1vY7WGcnxcZl"}},{"cell_type":"markdown","source":["### 2.7 텐서 생성 함수\n","\n","PyTorch는 다양한 텐서 생성 함수를 제공합니다."],"metadata":{"id":"uCqbG42I081Q"}},{"cell_type":"markdown","source":["| 함수 | 설명 |\n","|---|---|\n","| `torch.zeros()` |  모든 요소를 0으로 채운 텐서를 생성합니다. |\n","| `torch.ones()` | 모든 요소를 1로 채운 텐서를 생성합니다. |\n","| `torch.arange()` |  지정된 범위 내에서 순차적으로 증가하는 값을 가진 텐서를 생성합니다. |\n","| `torch.linspace()` | 시작값과 끝값 사이를 지정된 개수로 균등하게 나눈 값들로 텐서를 생성합니다. |\n","| `torch.rand()` | 0과 1 사이의 무작위 숫자를 균등 분포로 생성하여 텐서를 채웁니다. |\n","| `torch.randn()` | 표준 정규 분포 (평균 0, 표준편차 1)에서 난수를 생성하여 텐서를 채웁니다. |\n"],"metadata":{"id":"ZjN_QFOaLyyl"}},{"cell_type":"code","source":["# 텐서 생성 함수들\n","\n","# 0으로 채워진 1차원 텐서 생성 (크기: 5)\n","zeros_tensor = torch.zeros(5)\n","print(\"torch.zeros(5):\\n\", zeros_tensor)\n","print(\"설명: 0으로 채워진 크기가 5인 1차원 텐서를 생성합니다.\\n\")\n","\n","# 1로 채워진 2차원 텐서 생성 (크기: 3x3)\n","ones_tensor = torch.ones(3, 3)\n","print(\"torch.ones(3, 3):\\n\", ones_tensor)\n","print(\"설명: 1로 채워진 크기가 3x3인 2차원 텐서를 생성합니다.\\n\")\n","\n","# 0부터 10까지 2씩 증가하는 1차원 텐서 생성\n","arange_tensor = torch.arange(0, 10, 2)\n","print(\"torch.arange(0, 10, 2):\\n\", arange_tensor)\n","print(\"설명: 0부터 10까지 (10은 포함하지 않음) 2씩 증가하는 값을 가진 1차원 텐서를 생성합니다.\\n\")\n","\n","# 0부터 1까지 0.1씩 증가하는 1차원 텐서 생성 (소수점 가능)\n","arange_float_tensor = torch.arange(0, 1, 0.1)\n","print(\"torch.arange(0, 1, 0.1):\\n\", arange_float_tensor)\n","print(\"설명: 0부터 1까지 (1은 포함하지 않음) 0.1씩 증가하는 값을 가진 1차원 텐서를 생성합니다.\\n\")\n","\n","# 0부터 1까지 균등하게 5개의 값을 가진 1차원 텐서 생성\n","linspace_tensor = torch.linspace(0, 1, 5)\n","print(\"torch.linspace(0, 1, 5):\\n\", linspace_tensor)\n","print(\"설명: 0부터 1까지 (1을 포함) 균등하게 5개의 값을 가진 1차원 텐서를 생성합니다.\\n\")\n","\n","# 0과 1 사이의 균등 분포(0과 1 사이의 무작위 숫자를 균등 분포로 생성)에서 난수로 채워진 2차원 텐서 생성 (크기: 3x3)\n","rand_tensor = torch.rand(3, 3)\n","print(\"torch.rand(3, 3):\\n\", rand_tensor)\n","print(\"설명: 0과 1 사이의 균등 분포(0과 1 사이의 무작위 숫자를 균등 분포로 생성)에서 난수를 생성하여 크기가 3x3인 2차원 텐서를 생성합니다.\\n\")\n","\n","# 표준 정규 분포에서 난수로 채워진 2차원 텐서 생성 (크기: 3x3)\n","randn_tensor = torch.randn(3, 3)\n","print(\"torch.randn(3, 3):\\n\", randn_tensor)\n","print(\"설명: 표준 정규 분포 (평균 0, 표준편차 1)에서 난수를 생성하여 크기가 3x3인 2차원 텐서를 생성합니다.\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rg6JTtJjsWf","executionInfo":{"status":"ok","timestamp":1729612446546,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"0f3d3145-99c0-49ea-e243-251370b08df0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.zeros(5):\n"," tensor([0., 0., 0., 0., 0.])\n","설명: 0으로 채워진 크기가 5인 1차원 텐서를 생성합니다.\n","\n","torch.ones(3, 3):\n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","설명: 1로 채워진 크기가 3x3인 2차원 텐서를 생성합니다.\n","\n","torch.arange(0, 10, 2):\n"," tensor([0, 2, 4, 6, 8])\n","설명: 0부터 10까지 (10은 포함하지 않음) 2씩 증가하는 값을 가진 1차원 텐서를 생성합니다.\n","\n","torch.arange(0, 1, 0.1):\n"," tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n","        0.9000])\n","설명: 0부터 1까지 (1은 포함하지 않음) 0.1씩 증가하는 값을 가진 1차원 텐서를 생성합니다.\n","\n","torch.linspace(0, 1, 5):\n"," tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n","설명: 0부터 1까지 (1을 포함) 균등하게 5개의 값을 가진 1차원 텐서를 생성합니다.\n","\n","torch.rand(3, 3):\n"," tensor([[0.3942, 0.8994, 0.4867],\n","        [0.2668, 0.6442, 0.8004],\n","        [0.3993, 0.2800, 0.5691]])\n","설명: 0과 1 사이의 균등 분포(0과 1 사이의 무작위 숫자를 균등 분포로 생성)에서 난수를 생성하여 크기가 3x3인 2차원 텐서를 생성합니다.\n","\n","torch.randn(3, 3):\n"," tensor([[ 0.8162, -0.8794,  0.8699],\n","        [ 0.2118, -0.6875,  0.9797],\n","        [-0.7988,  0.7458, -0.4872]])\n","설명: 표준 정규 분포 (평균 0, 표준편차 1)에서 난수를 생성하여 크기가 3x3인 2차원 텐서를 생성합니다.\n","\n"]}]},{"cell_type":"markdown","source":["## 3. PyTorch의 연산\n","\n","PyTorch는 다양한 수학 함수와 유틸리티 함수를 제공하여, 텐서 간의 기본 연산부터 복잡한 행렬 연산까지 쉽게 수행할 수 있습니다.\n","\n","여기서는 기본적인 산술 연산, 행렬 곱셈, 통계 함수 등을 다뤄보도록 하겠습니다."],"metadata":{"id":"Y2aGj0Zxkw24"}},{"cell_type":"markdown","source":["### 3.1 기본적인 산술 연산\n","\n","- 요소별 연산\n","\n","    PyTorch에서는 덧셈(+), 뺄셈(-), 곱셈(*), 나눗셈(/)을 텐서의 각 요소에 대해 독립적으로 수행할 수 있습니다. 이는 NumPy와 유사하게 동작합니다.\n","\n","- 절댓값, 제곱근, 지수, 로그 연산\n","    \n","    PyTorch는 절댓값(torch.abs()), 제곱근(torch.sqrt()), 지수(torch.exp()), 로그(torch.log()) 등 다양한 수학적 연산을 제공합니다."],"metadata":{"id":"oIXNevf61RwK"}},{"cell_type":"code","source":["a = torch.tensor([1, 2, 3])\n","b = torch.tensor([4, 5, 6])\n","\n","print(f\"a + b = {a + b}\")  # 덧셈\n","print(f\"a - b = {a - b}\")  # 뺄셈\n","print(f\"a * b = {a * b}\")  # 요소별 곱셈\n","print(f\"a / b = {a / b}\")  # 요소별 나눗셈\n","\n","# 내적 계산\n","print(f\"내적: {torch.dot(a, b)}\")  # 두 벡터의 내적"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dCC1BgmClGMY","executionInfo":{"status":"ok","timestamp":1729612446546,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"b3f4319e-058c-48b6-f18f-27856ab37d46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a + b = tensor([5, 7, 9])\n","a - b = tensor([-3, -3, -3])\n","a * b = tensor([ 4, 10, 18])\n","a / b = tensor([0.2500, 0.4000, 0.5000])\n","내적: 32\n"]}]},{"cell_type":"markdown","source":["### 3.2 행렬 곱셈\n","\n","행렬 곱셈은 `@` 연산자나 `torch.matmul()`을 사용하여 수행할 수 있습니다.\n","\n","- @ 연산자:\n","\n","    - PyTorch에서도 @ 연산자를 사용하여 행렬 곱을 수행할 수 있습니다.\n","    - m1 @ m2는 torch.mm(m1, m2)와 동일한 결과를 반환합니다.\n","\n","\n","- torch.mm() 함수:\n","\n","    - PyTorch에서 행렬 곱을 수행하는 기본 함수입니다.\n","    - 두 개의 2차원 텐서를 입력으로 받아 행렬 곱을 계산합니다.\n","    - torch.mm(m1, m2)는 m1과 m2의 행렬 곱을 반환합니다."],"metadata":{"id":"PzKPXlkX1Ux8"}},{"cell_type":"code","source":["m1 = torch.tensor([[1, 2], [3, 4]])\n","m2 = torch.tensor([[5, 6], [7, 8]])\n","\n","# @ 연산자를 사용한 행렬 곱\n","print(f\"@ 연산자를 사용한 행렬 곱:\\n{m1 @ m2}\")\n","\n","# torch.mm() 함수를 사용한 행렬 곱\n","print(f\"torch.mm() 함수를 사용한 행렬 곱:\\n{torch.mm(m1, m2)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQnJzqd5Qh-C","executionInfo":{"status":"ok","timestamp":1729612446547,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"903af1b1-d1d4-40f2-b1f5-7b24919294c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["@ 연산자를 사용한 행렬 곱:\n","tensor([[19, 22],\n","        [43, 50]])\n","torch.mm() 함수를 사용한 행렬 곱:\n","tensor([[19, 22],\n","        [43, 50]])\n"]}]},{"cell_type":"markdown","source":["### 3.3 통계 함수\n","\n","PyTorch는 합계, 평균, 표준편차, 최대값 및 최소값 등의 통계 함수를 지원합니다. 이를 통해 데이터를 분석하거나 모델 학습 중 중요한 통계 정보를 쉽게 계산할 수 있습니다.\n","\n","- 합계: torch.sum()\n","- 평균: torch.mean()\n","- 표준편차: torch.std()\n","- 최대값, 최소값: torch.max(), torch.min()"],"metadata":{"id":"plBb2-lr1ZaY"}},{"cell_type":"code","source":["c = torch.randn(3, 3)  # 3x3 랜덤 행렬 생성\n","\n","print(f\"Random 3x3 matrix:\\n{c}\")\n","print(\"Sum of all elements:\", torch.sum(c))  # 모든 요소의 합\n","print(f\"Mean: {torch.mean(c)}\")  # 평균\n","print(f\"Standard deviation: {torch.std(c)}\")  # 표준편차\n","print(f\"Maximum: {torch.max(c)}\")  # 최대값\n","print(f\"Minimum: {torch.min(c)}\")  # 최소값"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97ElFL2JlHbK","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":566,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"057dc7da-6729-430c-b59d-0feb345ee861"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Random 3x3 matrix:\n","tensor([[-0.7608, -1.4594,  0.6063],\n","        [-0.2377, -0.6451, -0.7799],\n","        [ 1.0828,  0.1401,  1.3331]])\n","Sum of all elements: tensor(-0.7207)\n","Mean: -0.08007434010505676\n","Standard deviation: 0.9399940371513367\n","Maximum: 1.333120346069336\n","Minimum: -1.4594085216522217\n"]}]},{"cell_type":"markdown","source":["### 3.4 기타 연산\n","\n","- argmax 및 argmin: torch.argmax()와 torch.argmin()은 텐서의 최대값 또는 최소값의 인덱스를 반환합니다. 이를 통해 데이터에서 최대값 또는 최소값이 어디에 있는지 쉽게 알 수 있습니다."],"metadata":{"id":"8__81RfZA7xi"}},{"cell_type":"code","source":["d = torch.tensor([10, 20, 5, 15])\n","\n","print(\"Index of max value:\", torch.argmax(d))  # 최대값의 인덱스\n","print(\"Index of min value:\", torch.argmin(d))  # 최소값의 인덱스"],"metadata":{"id":"uXA2iHncBApD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"6db57bac-b6d0-4880-91cb-0d5c2080c652"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index of max value: tensor(1)\n","Index of min value: tensor(2)\n"]}]},{"cell_type":"markdown","source":["이와 같이 PyTorch는 텐서 연산을 쉽게 수행할 수 있도록 다양한 수학 함수와 유틸리티 함수를 제공합니다. 기본적인 산술 연산부터 행렬 곱셈, 통계 함수, 기타 유용한 함수들을 활용하여 딥러닝 모델을 구축하고 데이터를 처리할 수 있습니다."],"metadata":{"id":"mg3L2Xc5BE4F"}},{"cell_type":"markdown","source":["##4. PyTorch의 인덱싱과 슬라이싱\n","\n","PyTorch에서의 인덱싱과 슬라이싱은 NumPy와 매우 유사합니다.\n","\n","이를 통해 텐서의 특정 부분에 접근하거나 수정할 수 있으며, 데이터를 손쉽게 조작할 수 있습니다."],"metadata":{"id":"W2iwN44tjYDr"}},{"cell_type":"markdown","source":["### 4.1 기본 인덱싱\n","\n","- 인덱싱을 통해 텐서의 특정 위치에 있는 요소에 접근할 수 있습니다. 인덱스는 0부터 시작합니다.\n"],"metadata":{"id":"VYVA1tTlojMy"}},{"cell_type":"code","source":["# 예제 텐서 생성\n","a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","print(f\"Original tensor:\\n{a}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uAa_73W_Do8p","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"4d63f560-383f-4667-d558-77ad67ea5d0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original tensor:\n","tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])\n","\n"]}]},{"cell_type":"code","source":["# 특정 요소 접근\n","print(f\"Element at (0, 0): {a[0, 0]}\")  # 첫 번째 행, 첫 번째 열의 요소\n","print(f\"Element at (1, 2): {a[1, 2]}\")  # 두 번째 행, 세 번째 열의 요소"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mamU74Vx1gQa","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"4e01a9ca-c31c-4349-a699-decf9bf330ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Element at (0, 0): 1\n","Element at (1, 2): 6\n"]}]},{"cell_type":"code","source":["# 특정 행 접근\n","print(f\"First row: {a[0]}\")  # 첫 번째 행\n","print(f\"Last row: {a[-1]}\")  # 마지막 행"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qZfG9Ol1hmp","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"24805f8b-4485-4da1-b95a-dbaa2bd01473"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First row: tensor([1, 2, 3])\n","Last row: tensor([7, 8, 9])\n"]}]},{"cell_type":"code","source":["# 특정 열 접근\n","print(f\"Second column: {a[:, 1]}\")  # 두 번째 열"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvM_AOEZjY07","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"e1422c6f-5b98-4008-9a5d-be045db276f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Second column: tensor([2, 5, 8])\n"]}]},{"cell_type":"markdown","source":["### 4.2 슬라이싱\n","\n","- 슬라이싱은 start:end:step 형식으로 사용되며, 특정 부분의 텐서를 추출할 수 있습니다."],"metadata":{"id":"8oxRTIquQVAi"}},{"cell_type":"code","source":["# 슬라이싱으로 여러 행/열 접근\n","print(f\"First two rows:\\n{a[:2]}\")  # 처음 두 행\n","print(f\"Last two columns:\\n{a[:, -2:]}\")  # 마지막 두 열\n","print(f\"Rows 1 and 2, columns 0 and 1:\\n{a[0:2, 0:2]}\")  # 1, 2행과 0, 1열로 이루어진 부분 텐서"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXlpW7KQkDLi","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"a4f30da2-7779-4405-a8dd-01428d642d22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First two rows:\n","tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","Last two columns:\n","tensor([[2, 3],\n","        [5, 6],\n","        [8, 9]])\n","Rows 1 and 2, columns 0 and 1:\n","tensor([[1, 2],\n","        [4, 5]])\n"]}]},{"cell_type":"code","source":["# 특정 행/열 리스트로 접근\n","print(f\"Rows 0 and 2:\\n{a[[0, 2]]}\")  # 0번째 행과 2번째 행\n","print(f\"Columns 1 and 2:\\n{a[:, [1, 2]]}\")  # 1번째 열과 2번째 열"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFFlIxmCZCb4","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"03295c62-fb43-4737-9d4b-cfb1b833d6a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Rows 0 and 2:\n","tensor([[1, 2, 3],\n","        [7, 8, 9]])\n","Columns 1 and 2:\n","tensor([[2, 3],\n","        [5, 6],\n","        [8, 9]])\n"]}]},{"cell_type":"markdown","source":["### 4.3 고급 인덱싱"],"metadata":{"id":"XEABD20a2k6u"}},{"cell_type":"markdown","source":["#### 불리언 인덱싱\n","\n","- 조건을 만족하는 요소들만 선택할 수 있습니다."],"metadata":{"id":"sadJSCTG11OK"}},{"cell_type":"code","source":["# 불리언 인덱싱\n","mask = a > 5\n","print(f\"Elements greater than 5:\\n{a[mask]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJ3p_55415jv","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"fd159b88-2d93-4ee4-95c7-2bdf80265546"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Elements greater than 5:\n","tensor([6, 7, 8, 9])\n"]}]},{"cell_type":"markdown","source":["#### 정수 배열 인덱스\n","- 여러 행과 열에서 특정 요소를 선택할 수 있습니다."],"metadata":{"id":"uz7Leu5N17C4"}},{"cell_type":"code","source":["# 정수 배열 인덱싱\n","row_indices = torch.tensor([0, 2])\n","col_indices = torch.tensor([1, 2])\n","print(f\"Selected elements:\\n{a[row_indices[:, None], col_indices]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmDajnGP1_D1","executionInfo":{"status":"ok","timestamp":1729612447108,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"072d7c7f-44ce-4788-d364-5c4c5cc443bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Selected elements:\n","tensor([[2, 3],\n","        [8, 9]])\n"]}]},{"cell_type":"markdown","source":["#### 조건을 만족하는 요소 변경\n","\n","- 특정 조건을 만족하는 요소의 값을 변경할 수 있습니다."],"metadata":{"id":"xhPhUA9y2Bek"}},{"cell_type":"code","source":["a[a % 2 == 0] = 0  # 짝수를 0으로 변경\n","print(f\"After replacing even numbers with 0:\\n{a}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cu7UTW52fhN","executionInfo":{"status":"ok","timestamp":1729612447109,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"fd3adcde-c676-4278-b9e7-61999b5bcea7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["After replacing even numbers with 0:\n","tensor([[1, 0, 3],\n","        [0, 5, 0],\n","        [7, 0, 9]])\n"]}]},{"cell_type":"markdown","source":["### 4.4 2차원 텐서 인덱싱 & 슬라이싱"],"metadata":{"id":"BwNaX1Wb2ni7"}},{"cell_type":"code","source":["# 2차원 텐서 (행렬) 생성\n","b = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","print(\"원본 텐서 (행렬):\\n\", b)\n","\n","# 특정 요소 접근\n","print(\"\\n특정 요소 접근:\")\n","print(\"b[0, 0]:\", b[0, 0].item())  # 첫 번째 행, 첫 번째 열의 요소 (값만 출력)\n","print(\"b[1, 2]:\", b[1, 2].item())  # 두 번째 행, 세 번째 열의 요소 (값만 출력)\n","\n","# 행 접근\n","print(\"\\n행 접근:\")\n","print(\"b[1]:\\n\", b[1])  # 두 번째 행 (텐서로 출력)\n","\n","# 열 접근\n","print(\"\\n열 접근:\")\n","print(\"b[:, 1]:\\n\", b[:, 1])  # 두 번째 열 (텐서로 출력)\n","\n","# 부분 행렬 추출 (슬라이싱)\n","print(\"\\n부분 행렬 추출 (슬라이싱):\")\n","print(\"b[1:, 1:]:\\n\", b[1:, 1:])  # 두 번째 행부터, 두 번째 열부터 (텐서로 출력)\n","\n","# 행렬 덧셈\n","c = torch.tensor([[10, 11, 12], [13, 14, 15], [16, 17, 18]])\n","print(\"\\n행렬 덧셈:\")\n","print(\"b + c:\\n\", b + c)  # 행렬 덧셈\n","\n","# 행렬 곱셈\n","print(\"\\n행렬 곱셈:\")\n","print(\"b @ c:\\n\", b @ c)  # 행렬 곱셈"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3stYm_OkRFR","executionInfo":{"status":"ok","timestamp":1729612447109,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"fdc421eb-736d-4eb9-e5fd-408e6d42a3ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["원본 텐서 (행렬):\n"," tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])\n","\n","특정 요소 접근:\n","b[0, 0]: 1\n","b[1, 2]: 6\n","\n","행 접근:\n","b[1]:\n"," tensor([4, 5, 6])\n","\n","열 접근:\n","b[:, 1]:\n"," tensor([2, 5, 8])\n","\n","부분 행렬 추출 (슬라이싱):\n","b[1:, 1:]:\n"," tensor([[5, 6],\n","        [8, 9]])\n","\n","행렬 덧셈:\n","b + c:\n"," tensor([[11, 13, 15],\n","        [17, 19, 21],\n","        [23, 25, 27]])\n","\n","행렬 곱셈:\n","b @ c:\n"," tensor([[ 84,  90,  96],\n","        [201, 216, 231],\n","        [318, 342, 366]])\n"]}]},{"cell_type":"markdown","source":["### 4.5 3차원 텐서 인덱싱 & 슬라이싱"],"metadata":{"id":"dopM_skK2xkn"}},{"cell_type":"code","source":["# 3D 텐서 생성\n","A = torch.tensor([[[0,1,2,3],[4,5,6,7],[8,9,10,11]],\n","                  [[12,13,14,15],[16,17,18,19],[20,21,22,23]]])\n","\n","print(f\"3D tensor:\\n{A}\\n\")\n","print(f\"3D tensor shape: {A.shape}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2R3KnCre2et","executionInfo":{"status":"ok","timestamp":1729612447109,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"5e19471b-d570-4e37-eea1-00171a212608"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3D tensor:\n","tensor([[[ 0,  1,  2,  3],\n","         [ 4,  5,  6,  7],\n","         [ 8,  9, 10, 11]],\n","\n","        [[12, 13, 14, 15],\n","         [16, 17, 18, 19],\n","         [20, 21, 22, 23]]])\n","\n","3D tensor shape: torch.Size([2, 3, 4])\n","\n"]}]},{"cell_type":"code","source":["# 각 차원에 대한 설명\n","print(\"차원 설명:\")\n","print(\" - A[0]: 첫 번째 채널 (2차원 배열)\")\n","print(\" - A[1]: 두 번째 채널 (2차원 배열)\")\n","print(\" - A[0, 1]: 첫 번째 채널의 두 번째 행 (1차원 배열)\")\n","print(\" - A[1, 2]: 두 번째 채널의 세 번째 행 (1차원 배열)\")\n","print(\" - A[0, 1, 2]: 첫 번째 채널의 두 번째 행, 세 번째 열의 요소 (0부터 시작)\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P7DJcJMfe44G","executionInfo":{"status":"ok","timestamp":1729612447109,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"74002d15-1de1-4edc-e195-a9e39b6880e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["차원 설명:\n"," - A[0]: 첫 번째 채널 (2차원 배열)\n"," - A[1]: 두 번째 채널 (2차원 배열)\n"," - A[0, 1]: 첫 번째 채널의 두 번째 행 (1차원 배열)\n"," - A[1, 2]: 두 번째 채널의 세 번째 행 (1차원 배열)\n"," - A[0, 1, 2]: 첫 번째 채널의 두 번째 행, 세 번째 열의 요소 (0부터 시작)\n","\n"]}]},{"cell_type":"code","source":["# 다양한 인덱싱 예제 추가\n","print(\"인덱싱 예제:\")\n","print(f\"Element at (0,1,2): {A[0,1,2]}\")  # 6 출력\n","print(f\"Element at (1,0,3): {A[1,0,3]}\")  # 15 출력\n","print(f\"First channel:\\n{A[0]}\")\n","print(f\"Second row of the first channel: {A[0,1]}\")\n","print(f\"Third row of the second channel: {A[1,2]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0xmp5Phe6F8","executionInfo":{"status":"ok","timestamp":1729612447109,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"daf8c412-6307-431a-8cf1-9a64cb5bbd74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["인덱싱 예제:\n","Element at (0,1,2): 6\n","Element at (1,0,3): 15\n","First channel:\n","tensor([[ 0,  1,  2,  3],\n","        [ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11]])\n","Second row of the first channel: tensor([4, 5, 6, 7])\n","Third row of the second channel: tensor([20, 21, 22, 23])\n"]}]},{"cell_type":"markdown","source":["### 3D 텐서 형태: torch.Size([2, 3, 4]) 에 대한 설명\n","\n","3D tensor shape: torch.Size([2, 3, 4])는 생성한 텐서 A가 3차원 형태를 가지고 있으며, 그 크기가 torch.Size([2, 3, 4])임을 나타냅니다. 각 차원에 대해 자세히 살펴보겠습니다.\n","\n","1. 차원 0 (크기: 2): 이는 텐서의 채널 또는 깊이를 나타냅니다. 쉽게 말해, 2개의 2차원 배열이 서로 겹쳐져 있는 것으로 생각할 수 있습니다. A는 2개의 채널을 가지고 있으며, 각 채널은 독립적인 2차원 배열입니다.\n","2. 차원 1 (크기: 3): 이는 각 채널 또는 2차원 배열의 행의 수를 나타냅니다. A의 각 채널은 3개의 행을 가지고 있습니다.\n","3. 차원 2 (크기: 4): 이는 각 채널 또는 2차원 배열의 열의 수를 나타냅니다. A의 각 채널은 4개의 열을 가지고 있습니다.\n","시각적 표현:\n","\n","직육면체 상자 (3차원)를 상상해 보세요.\n","\n","- 상자는 2개의 칸으로 나뉘어져 위아래로 쌓여 있습니다 (채널).\n","- 각 칸은 3개의 행으로 나뉘어져 있습니다.\n","- 각 행은 4개의 열로 나뉘어져 있으며, 여기에 요소들이 저장됩니다.\n"],"metadata":{"id":"Dpzdq9XpcLYd"}},{"cell_type":"code","source":["# 시각화\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","tensor_np = A.numpy() # PyTorch 텐서를 NumPy 배열로 변환\n","fig, axs = plt.subplots(1, 2, figsize=(10, 5)) # 1행 2열의 서브플롯을 생성\n","\n","for i in range(tensor_np.shape[0]):\n","    im = axs[i].imshow(tensor_np[i], cmap='viridis') # 각 채널을 이미지로 표시\n","    axs[i].set_title(f'Channel {i}')\n","    axs[i].set_xlabel('Width')\n","    axs[i].set_ylabel('Height')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"ZrFhOFond8dv","executionInfo":{"status":"ok","timestamp":1729612449557,"user_tz":-540,"elapsed":2451,"user":{"displayName":"Hojin Lee","userId":"12540837793599289593"}},"outputId":"81506c52-9aae-4ead-8144-afcd8dd375bd"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA90AAAGECAYAAAAr0EOQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2i0lEQVR4nO3de1TU9b7/8deAMqg5KMXNxCuJdy2vWAkUhWkX221T62y1TLeFpRtPpud0tqmd2JbusnJ5OZacLp7cetJKyzIVTUVNE2+5TczU4wLvgqCiwvf3R7/GRkAB+TAXno+1Zi3mO9/v8P44zHr5Ypjv2CzLsgQAAAAAACqdn7sHAAAAAADAV1G6AQAAAAAwhNINAAAAAIAhlG4AAAAAAAyhdAMAAAAAYAilGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEfZLPZNHLkSHePUWlsNpteeeUVd48BAEClIq+B6oHSDXiR/fv3689//rOaNWumwMBAORwO3XnnnZo+fbrOnz/v7vE8wnvvvadWrVopMDBQt912m9555x13jwQAqGbI62ubOXOm+vXrp0aNGslms2nIkCHuHgkwqoa7BwBQNsuWLVO/fv1kt9s1aNAgtW3bVhcvXtS6dev04osvavfu3ZozZ467x3Sr2bNna8SIEXrssceUnJys7777Ti+88ILOnTunl156yd3jAQCqAfL6+qZMmaKzZ8+qa9euysrKcvc4gHGUbsALHDhwQAMGDFDjxo21atUqRUREOG9LSkpSZmamli1b5sYJ3e/8+fP693//d/Xp00eLFi2SJA0bNkxFRUWaPHmyhg8frvr167t5SgCALyOvy2bNmjXOV7lvuukmd48DGMeflwNe4PXXX1deXp7ee+89lwD/TVRUlEaNGlVs+5IlS9S2bVvZ7Xa1adNGy5cvd7n94MGDeu655xQdHa1atWrp5ptvVr9+/fTLL7+47Jeamiqbzab169crOTlZISEhqlOnjh599FEdP37cZd8mTZrowQcf1Lp169S1a1cFBgaqWbNm+uCDD4rNd+bMGY0ePVqRkZGy2+2KiorSlClTVFRUVO5/o9WrV+vkyZN67rnnXLYnJSUpPz+f/+QAAIwjr8umcePGstlsFToW8EaUbsALfPHFF2rWrJl69OhR5mPWrVun5557TgMGDNDrr7+uCxcu6LHHHtPJkyed+3z//ffasGGDBgwYoLffflsjRozQypUrFRcXp3PnzhW7z+eff17bt2/XhAkT9Oyzz+qLL74o8QQwmZmZ+uMf/6j77rtP06ZNU/369TVkyBDt3r3buc+5c+cUGxurjz76SIMGDdLbb7+tO++8U+PHj1dycnI5/4Wkbdu2SZI6d+7ssr1Tp07y8/Nz3g4AgCnkNYASWQA8Wk5OjiXJeuSRR8p8jCQrICDAyszMdG7bvn27Jcl65513nNvOnTtX7Nj09HRLkvXBBx84t82bN8+SZCUkJFhFRUXO7X/5y18sf39/68yZM85tjRs3tiRZa9eudW47duyYZbfbrTFjxji3TZ482apTp471008/uXz/cePGWf7+/tahQ4dc1jNhwoRrrjkpKcny9/cv8baQkBBrwIAB1zweAIAbQV6XLa+vVqdOHWvw4MHlOgbwNrzSDXi43NxcSVLdunXLdVxCQoKaN2/uvN6+fXs5HA79/PPPzm21atVyfn3p0iWdPHlSUVFRqlevnn744Ydi9zl8+HCXPwe7++67VVhYqIMHD7rs17p1a919993O6yEhIYqOjnb53gsXLtTdd9+t+vXr68SJE85LQkKCCgsLtXbt2nKt9/z58woICCjxtsDAQM4WCwAwirwGUBpOpAZ4OIfDIUk6e/ZsuY5r1KhRsW3169fX6dOnndfPnz+vlJQUzZs3T0eOHJFlWc7bcnJyrnufv52Y7Pf3WdbvvW/fPu3YsUMhISElzn/s2LESt5emVq1aunjxYom3XbhwweU/LAAAVDbyGkBpKN2Ah3M4HGrQoIF27dpVruP8/f1L3P77oH7++ec1b948jR49WjExMQoKCpLNZtOAAQNKPDlKWe6zrPsVFRXpvvvu09ixY0vct0WLFiVuL01ERIQKCwt17NgxhYaGOrdfvHhRJ0+eVIMGDcp1fwAAlAd5DaA0lG7ACzz44IOaM2eO0tPTFRMTU2n3u2jRIg0ePFjTpk1zbrtw4YLOnDlTad+jNM2bN1deXp4SEhIq5f46duwoSdqyZYt69+7t3L5lyxYVFRU5bwcAwBTyGkBJeE834AXGjh2rOnXq6JlnntHRo0eL3b5//35Nnz693Pfr7+9f7Lfe77zzjgoLCys8a1k9/vjjSk9P19dff13stjNnzujy5cvlur977rlHwcHBmjlzpsv2mTNnqnbt2urTp88NzQsAwPWQ1wBKwivdgBdo3ry55s+fr/79+6tVq1YaNGiQ2rZtq4sXL2rDhg1auHChhgwZUu77ffDBB/Xhhx8qKChIrVu3Vnp6ur799lvdfPPNlb+Iq7z44ov6/PPP9eCDD2rIkCHq1KmT8vPztXPnTi1atEi//PKLbrnlljLfX61atTR58mQlJSWpX79+SkxM1HfffaePPvpI//mf/6ng4GCDqwEAgLwuqy+++ELbt2+X9OuJ4Xbs2KFXX31VkvTwww+rffv2lb4OwJ0o3YCXePjhh7Vjxw698cYb+uyzzzRz5kzZ7Xa1b99e06ZN07Bhw8p9n9OnT5e/v78+/vhjXbhwQXfeeae+/fZbJSYmGliBq9q1a2vNmjV67bXXtHDhQn3wwQdyOBxq0aKFJk6cqKCgoHLf53PPPaeaNWtq2rRp+vzzzxUZGak333xTo0aNMrACAACKI6+v73//93/13//9387r27Zt07Zt2yRJDRs2pHTD59isq/9WBQAAAAAAVAre0w0AAAAAgCGUbgAAAAAADKF0AwAAAABgiNeU7lOnTunJJ5+Uw+FQvXr1NHToUOXl5V3zmLi4ONlsNpfLiBEjqmhiAACqJzIbAIArvOZEag888ICysrI0e/ZsXbp0SU899ZS6dOmi+fPnl3pMXFycWrRooUmTJjm31a5dWw6HoypGBgCgWiKzAQC4wis+MmzPnj1avny5vv/+e3Xu3FmS9M4776h3796aOnWqGjRoUOqxtWvXVnh4eFWNCgBAtUZmAwDgyitKd3p6uurVq+cMb0lKSEiQn5+fNm3apEcffbTUYz/++GN99NFHCg8P10MPPaT/+I//UO3atUvdv6CgQAUFBc7rRUVFOnXqlG6++WbZbLbKWRAAoNqxLEtnz55VgwYN5OfnNe/uKreqymzyGgBggom89orSnZ2drdDQUJdtNWrUUHBwsLKzs0s97oknnlDjxo3VoEED7dixQy+99JL27t2rTz/9tNRjUlJSNHHixEqbHQCA3zt8+LAaNmzo7jGMqarMJq8BACZVZl67tXSPGzdOU6ZMueY+e/bsqfD9Dx8+3Pl1u3btFBERoXvvvVf79+9X8+bNSzxm/PjxSk5Odl7PyclRo0aNdJd6q4ZqVngWVK4ajX33P6ze6mKD+u4eAVc5FxHo7hHwO4WXLmjbF6+qbt267h6lQjwts8lr70Beex7y2vOQ157FRF67tXSPGTNGQ4YMueY+zZo1U3h4uI4dO+ay/fLlyzp16lS53vvVrVs3SVJmZmappdtut8tutxfbXkM1VcNGiHuKGn7FHyO4V1ENAsPT1KjJY+KJvPVPnz0ts8lr70Beex7y2vOQ156pMvParaU7JCREISEh190vJiZGZ86c0datW9WpUydJ0qpVq1RUVOQM5bLIyMiQJEVERFRoXgAAqisyGwCAivGKM7m0atVKvXr10rBhw7R582atX79eI0eO1IABA5xnQT1y5IhatmypzZs3S5L279+vyZMna+vWrfrll1/0+eefa9CgQerZs6fat2/vzuUAAOCzyGwAAFx5RemWfj2jacuWLXXvvfeqd+/euuuuuzRnzhzn7ZcuXdLevXt17tw5SVJAQIC+/fZb3X///WrZsqXGjBmjxx57TF988YW7lgAAQLVAZgMAcIVXnL1ckoKDgzV//vxSb2/SpIksy3Jej4yM1Jo1a6piNAAA8DtkNgAAV3jNK90AAAAAAHgbSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADKF0AwAAAABgCKUbAAAAAABDKN0AAAAAABhC6QYAAAAAwBBKNwAAAAAAhlC6AQAAAAAwhNINAAAAAIAhlG4AAAAAAAyhdAMAAAAAYAilGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADKF0AwAAAABgCKUbAAAAAABDvK50z5gxQ02aNFFgYKC6deumzZs3X3P/hQsXqmXLlgoMDFS7du305ZdfVtGkAABUb2Q2AABeVroXLFig5ORkTZgwQT/88IM6dOigxMREHTt2rMT9N2zYoIEDB2ro0KHatm2b+vbtq759+2rXrl1VPDkAANULmQ0AwK9slmVZ7h6irLp166YuXbro3XfflSQVFRUpMjJSzz//vMaNG1ds//79+ys/P19Lly51buvevbs6duyoWbNmlel75ubmKigoSHF6RDVsNStnIbhhNZo0cvcIuMrFhsHuHgFXOdcg0N0j4HcuX7qgLZ++rJycHDkcDnePY1xVZzZ57ZnIa89DXnse8tqzmMhrr3ml++LFi9q6dasSEhKc2/z8/JSQkKD09PQSj0lPT3fZX5ISExNL3V+SCgoKlJub63IBAABlVxWZTV4DALyF15TuEydOqLCwUGFhYS7bw8LClJ2dXeIx2dnZ5dpfklJSUhQUFOS8REZG3vjwAABUI1WR2eQ1AMBbeE3prirjx49XTk6O83L48GF3jwQAAK5CXgMAvEUNdw9QVrfccov8/f119OhRl+1Hjx5VeHh4iceEh4eXa39JstvtstvtNz4wAADVVFVkNnkNAPAWXvNKd0BAgDp16qSVK1c6txUVFWnlypWKiYkp8ZiYmBiX/SVpxYoVpe4PAABuHJkNAMAVXvNKtyQlJydr8ODB6ty5s7p27aq33npL+fn5euqppyRJgwYN0q233qqUlBRJ0qhRoxQbG6tp06apT58++uSTT7RlyxbNmTPHncsAAMDnkdkAAPzKq0p3//79dfz4cf31r39Vdna2OnbsqOXLlztPvHLo0CH5+V158b5Hjx6aP3++Xn75Zf3bv/2bbrvtNi1ZskRt27Z11xIAAKgWyGwAAH7lVZ/T7Q587qdn4nM/PQ+f++l5+NxPz1LdPqe7qpHXnom89jzktechrz1Ltf6cbgAAAAAAvA2lGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADKF0AwAAAABgCKUbAAAAAABDKN0AAAAAABhC6QYAAAAAwBBKNwAAAAAAhlC6AQAAAAAwhNINAAAAAIAhlG4AAAAAAAyhdAMAAAAAYAilGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADPG60j1jxgw1adJEgYGB6tatmzZv3lzqvqmpqbLZbC6XwMDAKpwWAIDqi8wGAMDLSveCBQuUnJysCRMm6IcfflCHDh2UmJioY8eOlXqMw+FQVlaW83Lw4MEqnBgAgOqJzAYA4FdeVbr//ve/a9iwYXrqqafUunVrzZo1S7Vr19b7779f6jE2m03h4eHOS1hYWBVODABA9URmAwDwK68p3RcvXtTWrVuVkJDg3Obn56eEhASlp6eXelxeXp4aN26syMhIPfLII9q9e/c1v09BQYFyc3NdLgAAoOyqIrPJawCAt6jh7gHK6sSJEyosLCz2W++wsDD985//LPGY6Ohovf/++2rfvr1ycnI0depU9ejRQ7t371bDhg1LPCYlJUUTJ04stv3YiG7yt/PeMk9xPtRy9wi4ysWQy+4eAVe5KZQS4kkKzxVIn7p7iqpRFZlNXnsH8trzkNeeh7z2LCby2mte6a6ImJgYDRo0SB07dlRsbKw+/fRThYSEaPbs2aUeM378eOXk5Dgvhw8frsKJAQConsqb2eQ1AMBbeM0r3bfccov8/f119OhRl+1Hjx5VeHh4me6jZs2auv3225WZmVnqPna7XXa7/YZmBQCgOquKzCavAQDewmte6Q4ICFCnTp20cuVK57aioiKtXLlSMTExZbqPwsJC7dy5UxEREabGBACg2iOzAQC4wmte6Zak5ORkDR48WJ07d1bXrl311ltvKT8/X0899ZQkadCgQbr11luVkpIiSZo0aZK6d++uqKgonTlzRm+88YYOHjyoZ555xp3LAADA55HZAAD8yqtKd//+/XX8+HH99a9/VXZ2tjp27Kjly5c7T9Ry6NAh+fldefH+9OnTGjZsmLKzs1W/fn116tRJGzZsUOvWrd21BAAAqgUyGwCAX9ksy+K0kteQm5uroKAgtR7xGmdD9SCcDdXzcDZUz3NTaL67R8DvFJ4r0N4npignJ0cOh8Pd4/gc8tozkdeeh7z2POS1ZzGR117znm4AAAAAALwNpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADKF0AwAAAABgCKUbAAAAAABDKN0AAAAAABhC6QYAAAAAwBBKNwAAAAAAhlC6AQAAAAAwhNINAAAAAIAhlG4AAAAAAAyhdAMAAAAAYAilGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMqVDpnjRpks6dO1ds+/nz5zVp0qQbHgoAAFQOMhsAAPeqUOmeOHGi8vLyim0/d+6cJk6ceMNDAQCAykFmAwDgXhUq3ZZlyWazFdu+fft2BQcH3/BQAACgcpDZAAC4V43y7Fy/fn3ZbDbZbDa1aNHCJcQLCwuVl5enESNGVPqQAACgfMhsAAA8Q7lK91tvvSXLsvT0009r4sSJCgoKct4WEBCgJk2aKCYmptKHBAAA5UNmAwDgGcpVugcPHixJatq0qXr06KGaNWsaGQoAANwYMhsAAM9QrtL9m9jYWBUVFemnn37SsWPHVFRU5HJ7z549K2U4AABwY8hsAADcq0Kle+PGjXriiSd08OBBWZblcpvNZlNhYWGlDAcAAG4MmQ0AgHtVqHSPGDFCnTt31rJlyxQREVHiWVEBAID7kdkAALhXhUr3vn37tGjRIkVFRVX2PAAAoBKR2QAAuFeFPqe7W7duyszMrOxZAABAJSOzAQBwrzK/0r1jxw7n188//7zGjBmj7OxstWvXrtgZUdu3b195EwIAgHIhswEA8BxlLt0dO3aUzWZzOQnL008/7fz6t9s4KQsAAO5FZgMA4DnKXLoPHDhgcg4AAFBJyGwAADxHmUt348aNTc4BAAAqCZkNAIDnqNDZyz///PMSt9tsNgUGBioqKkpNmza9ocFKsnbtWr3xxhvaunWrsrKytHjxYvXt2/eax6SlpSk5OVm7d+9WZGSkXn75ZQ0ZMqTSZwMAwBO5I7PJawAArqhQ6e7bt2+x94pJru8Ru+uuu7RkyRLVr1+/UgaVpPz8fHXo0EFPP/20/vCHP1x3/wMHDqhPnz4aMWKEPv74Y61cuVLPPPOMIiIilJiYWGlzAQDgqdyR2eQ1AABXVOgjw1asWKEuXbpoxYoVysnJUU5OjlasWKFu3bpp6dKlWrt2rU6ePKl//dd/rdRhH3jgAb366qt69NFHy7T/rFmz1LRpU02bNk2tWrXSyJEj9cc//lFvvvlmpc4FAICnckdmk9cAAFxRoVe6R40apTlz5qhHjx7Obffee68CAwM1fPhw7d69W2+99ZbLmVLdIT09XQkJCS7bEhMTNXr06FKPKSgoUEFBgfN6bm6uqfEAADDOGzKbvAYA+LIKvdK9f/9+ORyOYtsdDod+/vlnSdJtt92mEydO3Nh0Nyg7O1thYWEu28LCwpSbm6vz58+XeExKSoqCgoKcl8jIyKoYFQAAI7whs8lrAIAvq1Dp7tSpk1588UUdP37cue348eMaO3asunTpIknat2+fVwbg+PHjnX9+l5OTo8OHD7t7JAAAKsxXM5u8BgB4iwr9efl7772nRx55RA0bNnSG9OHDh9WsWTN99tlnkqS8vDy9/PLLlTdpBYSHh+vo0aMu244ePSqHw6FatWqVeIzdbpfdbq+K8QAAMM4bMpu8BgD4sgqV7ujoaP3444/65ptv9NNPPzm33XffffLz+/XF8+t9NEhViImJ0ZdffumybcWKFYqJiXHTRAAAVC1vyGzyGgDgyypUuiXJz89PvXr1Uq9evSpznmvKy8tTZmam8/qBAweUkZGh4OBgNWrUSOPHj9eRI0f0wQcfSJJGjBihd999V2PHjtXTTz+tVatW6R//+IeWLVtWZTMDAOBuVZ3Z5DUAAFeUuXS//fbbGj58uAIDA/X2229fc98XXnjhhgcryZYtWxQfH++8npycLEkaPHiwUlNTlZWVpUOHDjlvb9q0qZYtW6a//OUvmj59uho2bKi5c+fymZ8AAJ/m7swmrwEAuMJmWZZVlh2bNm2qLVu26Oabb1bTpk1Lv0ObzXk2VF+Qm5uroKAgtR7xmvztge4eB//f+dAy/diiCl0MuezuEXCVm0Lz3T0CfqfwXIH2PjFFOTk5JZ5NvDJVx8wmrz0Tee15yGvPQ157FhN5XeZXug8cOFDi1wAAwLOQ2QAAeI4KfWTYby5evKi9e/fq8mV+YwYAgCcjswEAcI8Kle5z585p6NChql27ttq0aeN8X9bzzz+vv/3tb5U6IAAAqDgyGwAA96pQ6R4/fry2b9+utLQ0BQZeed9UQkKCFixYUGnDAQCAG0NmAwDgXhX6yLAlS5ZowYIF6t69u2w2m3N7mzZttH///kobDgAA3BgyGwAA96rQK93Hjx9XaGhose35+fkugQ4AANyLzAYAwL0qVLo7d+6sZcuWOa//Ftpz585VTExM5UwGAABuGJkNAIB7VejPy1977TU98MAD+vHHH3X58mVNnz5dP/74ozZs2KA1a9ZU9owAAKCCyGwAANyrQq9033XXXcrIyNDly5fVrl07ffPNNwoNDVV6ero6depU2TMCAIAKIrMBAHCvcr3SnZub6/w6JCRE06ZNK3Efh8Nx45MBAIAKI7MBAPAM5Srd9erVu+ZJVyzLks1mU2Fh4Q0PBgAAKo7MBgDAM5SrdK9evdr5tWVZ6t27t+bOnatbb7210gcDAAAVR2YDAOAZylW6Y2NjXa77+/ure/fuatasWaUOBQAAbgyZDQCAZ6jQidQAAAAAAMD1UboBAAAAADDkhkv3tU7SAgAAPAeZDQBA1SvXe7r/8Ic/uFy/cOGCRowYoTp16rhs//TTT298MgAAUGFkNgAAnqFcpTsoKMjl+r/8y79U6jAAAKBykNkAAHiGcpXuefPmmZoDAABUIjIbAADPwInUAAAAAAAwhNINAAAAAIAhlG4AAAAAAAyhdAMAAAAAYAilGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADKF0AwAAAABgCKUbAAAAAABDvKp0r127Vg899JAaNGggm82mJUuWXHP/tLQ02Wy2Ypfs7OyqGRgAgGqIvAYA4AqvKt35+fnq0KGDZsyYUa7j9u7dq6ysLOclNDTU0IQAAIC8BgDgihruHqA8HnjgAT3wwAPlPi40NFT16tWr/IEAAEAx5DUAAFd41SvdFdWxY0dFRETovvvu0/r166+5b0FBgXJzc10uAADAPPIaAOCLvOqV7vKKiIjQrFmz1LlzZxUUFGju3LmKi4vTpk2bdMcdd5R4TEpKiiZOnFhse7NHM1WzToDpkVFGXeoddPcIuMpddfa6ewRc5c7AavF7Va+Re7ZI9d09hIcir30Xee15yGvPQ157FhN57dOlOzo6WtHR0c7rPXr00P79+/Xmm2/qww8/LPGY8ePHKzk52Xk9NzdXkZGRxmcFAKC6Iq8BAL7Mp0t3Sbp27ap169aVervdbpfdbq/CiQAAwNXIawCAr6h2f8uQkZGhiIgId48BAACugbwGAPgKr3qlOy8vT5mZmc7rBw4cUEZGhoKDg9WoUSONHz9eR44c0QcffCBJeuutt9S0aVO1adNGFy5c0Ny5c7Vq1Sp988037loCAAA+j7wGAOAKryrdW7ZsUXx8vPP6b+/lGjx4sFJTU5WVlaVDhw45b7948aLGjBmjI0eOqHbt2mrfvr2+/fZbl/sAAACVi7wGAOAKm2VZlruH8GS5ubkKCgrSg18/zdlQPQhnQ/U8nA3V83A2VM+Se7ZI9Vv8rJycHDkcDneP43PIa89EXnse8trzkNeexURe8wgDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADKF0AwAAAABgCKUbAAAAAABDKN0AAAAAABhC6QYAAAAAwBBKNwAAAAAAhlC6AQAAAAAwhNINAAAAAIAhlG4AAAAAAAyhdAMAAAAAYAilGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADKF0AwAAAABgCKUbAAAAAABDKN0AAAAAABhC6QYAAAAAwBBKNwAAAAAAhlC6AQAAAAAwhNINAAAAAIAhXlO6U1JS1KVLF9WtW1ehoaHq27ev9u7de93jFi5cqJYtWyowMFDt2rXTl19+WQXTAgBQfZHZAABc4TWle82aNUpKStLGjRu1YsUKXbp0Sffff7/y8/NLPWbDhg0aOHCghg4dqm3btqlv377q27evdu3aVYWTAwBQvZDZAABcYbMsy3L3EBVx/PhxhYaGas2aNerZs2eJ+/Tv31/5+flaunSpc1v37t3VsWNHzZo1q0zfJzc3V0FBQXrw66dVs05ApcyOG9el3kF3j4Cr3FXn+q9ioWrdGeg1v1etFnLPFql+i5+Vk5Mjh8Ph7nGqVFVkNnntmchrz0Neex7y2rOYyGuvfYRzcnIkScHBwaXuk56eroSEBJdtiYmJSk9PL/WYgoIC5ebmulwAAEDFmchs8hoA4C28snQXFRVp9OjRuvPOO9W2bdtS98vOzlZYWJjLtrCwMGVnZ5d6TEpKioKCgpyXyMjISpsbAIDqxlRmk9cAAG/hlaU7KSlJu3bt0ieffFLp9z1+/Hjl5OQ4L4cPH6707wEAQHVhKrPJawCAt6jh7gHKa+TIkVq6dKnWrl2rhg0bXnPf8PBwHT161GXb0aNHFR4eXuoxdrtddru9UmYFAKA6M5nZ5DUAwFt4zSvdlmVp5MiRWrx4sVatWqWmTZte95iYmBitXLnSZduKFSsUExNjakwAAKo9MhsAgCu85pXupKQkzZ8/X5999pnq1q3rfI9XUFCQatWqJUkaNGiQbr31VqWkpEiSRo0apdjYWE2bNk19+vTRJ598oi1btmjOnDluWwcAAL6OzAYA4AqveaV75syZysnJUVxcnCIiIpyXBQsWOPc5dOiQsrKynNd79Oih+fPna86cOerQoYMWLVqkJUuWXPNELgAA4MaQ2QAAXOE1r3SX5ePE09LSim3r16+f+vXrZ2AiAABQEjIbAIArvOaVbgAAAAAAvA2lGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADKF0AwAAAABgCKUbAAAAAABDKN0AAAAAABhC6QYAAAAAwBBKNwAAAAAAhlC6AQAAAAAwhNINAAAAAIAhlG4AAAAAAAyhdAMAAAAAYAilGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACGULoBAAAAADCE0g0AAAAAgCGUbgAAAAAADPGa0p2SkqIuXbqobt26Cg0NVd++fbV3795rHpOamiqbzeZyCQwMrKKJAQConshsAACu8JrSvWbNGiUlJWnjxo1asWKFLl26pPvvv1/5+fnXPM7hcCgrK8t5OXjwYBVNDABA9URmAwBwRQ13D1BWy5cvd7mempqq0NBQbd26VT179iz1OJvNpvDwcNPjAQCA/4/MBgDgCq8p3VfLycmRJAUHB19zv7y8PDVu3FhFRUW644479Nprr6lNmzal7l9QUKCCgoJi3+dS/sVKmBqV5UKNS+4eAVfJLypy9wi4Si5PE4+Sm/frc8SyLDdPUvVMZDZ57R3Ia89DXnse8tqzmMhrm+WF6V9UVKSHH35YZ86c0bp160rdLz09Xfv27VP79u2Vk5OjqVOnau3atdq9e7caNmxY4jGvvPKKJk6caGp0AEA1t3//fjVr1szdY1QZU5lNXgMATKrMvPbK0v3ss8/qq6++0rp160otzyW5dOmSWrVqpYEDB2ry5Mkl7nP1b87PnDmjxo0b69ChQwoKCrrh2d0lNzdXkZGROnz4sBwOh7vHuSG+shZfWYfkO2vxlXVIvrMWX1mH9OsrsY0aNdLp06dVr149d49TZUxltq/mteQ7P/e+sg7Jd9biK+uQfGctvrIOyXfWYiKvve7Py0eOHKmlS5dq7dq15QpvSapZs6Zuv/12ZWZmlrqP3W6X3W4vtj0oKMirf3h+43A4fGIdku+sxVfWIfnOWnxlHZLvrMVX1iFJfn5ecw7TG2Yys309ryXf+bn3lXVIvrMWX1mH5Dtr8ZV1SL6zlsrMa69JfsuyNHLkSC1evFirVq1S06ZNy30fhYWF2rlzpyIiIgxMCAAAJDIbAIDf85pXupOSkjR//nx99tlnqlu3rrKzsyX9+hvtWrVqSZIGDRqkW2+9VSkpKZKkSZMmqXv37oqKitKZM2f0xhtv6ODBg3rmmWfctg4AAHwdmQ0AwBVeU7pnzpwpSYqLi3PZPm/ePA0ZMkSSdOjQIZc/Azh9+rSGDRum7Oxs1a9fX506ddKGDRvUunXrMn9fu92uCRMmlPgnbN7EV9Yh+c5afGUdku+sxVfWIfnOWnxlHZJvreV63JHZvvTv6ytr8ZV1SL6zFl9Zh+Q7a/GVdUi+sxYT6/DKE6kBAAAAAOANvOY93QAAAAAAeBtKNwAAAAAAhlC6AQAAAAAwhNINAAAAAIAhlO6rnDp1Sk8++aQcDofq1aunoUOHKi8v75rHxMXFyWazuVxGjBhRRRNfMWPGDDVp0kSBgYHq1q2bNm/efM39Fy5cqJYtWyowMFDt2rXTl19+WUWTXl951pKamlrs3z8wMLAKpy3Z2rVr9dBDD6lBgway2WxasmTJdY9JS0vTHXfcIbvdrqioKKWmphqf83rKu460tLRij4fNZnN+ZJC7pKSkqEuXLqpbt65CQ0PVt29f7d2797rHeeLzpCJr8cTnycyZM9W+fXs5HA45HA7FxMToq6++uuYxnvh4SOVfiyc+Ht6IzHY/8tpz8loisz3teeIreS35Tma7K68p3Vd58skntXv3bq1YsUJLly7V2rVrNXz48OseN2zYMGVlZTkvr7/+ehVMe8WCBQuUnJysCRMm6IcfflCHDh2UmJioY8eOlbj/hg0bNHDgQA0dOlTbtm1T37591bdvX+3atatK5y5JedciSQ6Hw+Xf/+DBg1U4ccny8/PVoUMHzZgxo0z7HzhwQH369FF8fLwyMjI0evRoPfPMM/r6668NT3pt5V3Hb/bu3evymISGhhqasGzWrFmjpKQkbdy4UStWrNClS5d0//33Kz8/v9RjPPV5UpG1SJ73PGnYsKH+9re/aevWrdqyZYvuuecePfLII9q9e3eJ+3vq4yGVfy2S5z0e3ojMdu/PPnntWXktkdme9jzxlbyWfCez3ZbXFpx+/PFHS5L1/fffO7d99dVXls1ms44cOVLqcbGxsdaoUaOqYMLSde3a1UpKSnJeLywstBo0aGClpKSUuP/jjz9u9enTx2Vbt27drD//+c9G5yyL8q5l3rx5VlBQUBVNVzGSrMWLF19zn7Fjx1pt2rRx2da/f38rMTHR4GTlU5Z1rF692pJknT59ukpmqqhjx45Zkqw1a9aUuo8nP09+ryxr8YbniWVZVv369a25c+eWeJu3PB6/udZavOXx8GRktvt/9snrKzwtry2LzLYsz3ie/J4v5bVl+U5mV0Ve80r376Snp6tevXrq3Lmzc1tCQoL8/Py0adOmax778ccf65ZbblHbtm01fvx4nTt3zvS4ThcvXtTWrVuVkJDg3Obn56eEhASlp6eXeEx6errL/pKUmJhY6v5VpSJrkaS8vDw1btxYkZGR1/1tlafy1Mekojp27KiIiAjdd999Wr9+vbvHKSYnJ0eSFBwcXOo+3vKYlGUtkmc/TwoLC/XJJ58oPz9fMTExJe7jLY9HWdYiefbj4Q3IbPf+7JPXnvV43Cgyu2r4Ql5LvpPZVZnXNW5kUF+TnZ1d7M9patSooeDg4Gu+t+WJJ55Q48aN1aBBA+3YsUMvvfSS9u7dq08//dT0yJKkEydOqLCwUGFhYS7bw8LC9M9//rPEY7Kzs0vc393v4anIWqKjo/X++++rffv2ysnJ0dSpU9WjRw/t3r1bDRs2rIqxK0Vpj0lubq7Onz+vWrVquWmy8omIiNCsWbPUuXNnFRQUaO7cuYqLi9OmTZt0xx13uHs8SVJRUZFGjx6tO++8U23bti11P099nvxeWdfiqc+TnTt3KiYmRhcuXNBNN92kxYsXq3Xr1iXu6+mPR3nW4qmPhzchs937s09ee39eS2R2VfL2vJZ8J7PdkdfVonSPGzdOU6ZMueY+e/bsqfD9//79Y+3atVNERITuvfde7d+/X82bN6/w/aJsYmJiXH471aNHD7Vq1UqzZ8/W5MmT3ThZ9RQdHa3o6Gjn9R49emj//v1688039eGHH7pxsiuSkpK0a9curVu3zt2j3LCyrsVTnyfR0dHKyMhQTk6OFi1apMGDB2vNmjWlhp8nK89aPPXx8ARktu/i597zkNlVx9vzWvKdzHZHXleL0j1mzBgNGTLkmvs0a9ZM4eHhxU7+cfnyZZ06dUrh4eFl/n7dunWTJGVmZlZJgN9yyy3y9/fX0aNHXbYfPXq01LnDw8PLtX9VqcharlazZk3dfvvtyszMNDGiMaU9Jg6Hw6t+a16Srl27ekxYjhw50nnCpev9htJTnye/Kc9aruYpz5OAgABFRUVJkjp16qTvv/9e06dP1+zZs4vt6+mPR3nWcjVPeTw8AZldnCf+7JPXvpnXEpltgi/kteQ7me2OvK4W7+kOCQlRy5Ytr3kJCAhQTEyMzpw5o61btzqPXbVqlYqKipyhXBYZGRmSfv2TnaoQEBCgTp06aeXKlc5tRUVFWrlyZanvT4iJiXHZX5JWrFhxzfczVIWKrOVqhYWF2rlzZ5X9+1cWT31MKkNGRobbHw/LsjRy5EgtXrxYq1atUtOmTa97jKc+JhVZy9U89XlSVFSkgoKCEm/z1MejNNday9U89fFwBzK7OE/82SevPevxqExkduXx5byWfCezqySvb/hUbD6mV69e1u23325t2rTJWrdunXXbbbdZAwcOdN7+f//3f1Z0dLS1adMmy7IsKzMz05o0aZK1ZcsW68CBA9Znn31mNWvWzOrZs2eVzv3JJ59YdrvdSk1NtX788Udr+PDhVr169azs7GzLsizrT3/6kzVu3Djn/uvXr7dq1KhhTZ061dqzZ481YcIEq2bNmtbOnTurdO6SlHctEydOtL7++mtr//791tatW60BAwZYgYGB1u7du921BMuyLOvs2bPWtm3brG3btlmSrL///e/Wtm3brIMHD1qWZVnjxo2z/vSnPzn3//nnn63atWtbL774orVnzx5rxowZlr+/v7V8+XJ3LcGyrPKv480337SWLFli7du3z9q5c6c1atQoy8/Pz/r222/dtQTLsizr2WeftYKCgqy0tDQrKyvLeTl37pxzH295nlRkLZ74PBk3bpy1Zs0a68CBA9aOHTuscePGWTabzfrmm28sy/Kex8Oyyr8WT3w8vBGZ7d6fffLas/LasshsT3ue+EpeW5bvZLa78prSfZWTJ09aAwcOtG666SbL4XBYTz31lHX27Fnn7QcOHLAkWatXr7Ysy7IOHTpk9ezZ0woODrbsdrsVFRVlvfjii1ZOTk6Vz/7OO+9YjRo1sgICAqyuXbtaGzdudN4WGxtrDR482GX/f/zjH1aLFi2sgIAAq02bNtayZcuqeOLSlWcto0ePdu4bFhZm9e7d2/rhhx/cMLWr3z6G4+rLb7MPHjzYio2NLXZMx44drYCAAKtZs2bWvHnzqnzuq5V3HVOmTLGaN29uBQYGWsHBwVZcXJy1atUq9wz/OyWtQZLLv7G3PE8qshZPfJ48/fTTVuPGja2AgAArJCTEuvfee52hZ1ne83hYVvnX4omPhzcis92PvPacvLYsMtvTnie+kteW5TuZ7a68tlmWZZXvtXEAAAAAAFAW1eI93QAAAAAAuAOlGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAGWWlpYmm82mM2fOlLpPamqq6tWrd937stlsWrJkSaXNBgAAfkVeA56F0g1UU7NmzVLdunV1+fJl57a8vDzVrFlTcXFxLvv+Ft4RERHKyspSUFBQmb/PK6+8oo4dO1bS1AAAVC/kNeD9KN1ANRUfH6+8vDxt2bLFue27775TeHi4Nm3apAsXLji3r169Wo0aNVJ0dLTCw8Nls9ncMTIAANUOeQ14P0o3UE1FR0crIiJCaWlpzm1paWl65JFH1LRpU23cuNFle3x8fIl/rpaamqpGjRqpdu3aevTRR3Xy5EmX2yZOnKjt27fLZrPJZrMpNTXVefuJEyf06KOPqnbt2rrtttv0+eefm1wyAABeh7wGvB+lG6jG4uPjtXr1auf11atXKy4uTrGxsc7t58+f16ZNmxQfH1/s+E2bNmno0KEaOXKkMjIyFB8fr1dffdV5e//+/TVmzBi1adNGWVlZysrKUv/+/Z23T5w4UY8//rh27Nih3r1768knn9SpU6cMrhgAAO9DXgPejdINVGPx8fFav369Ll++rLNnz2rbtm2KjY1Vz549nb9RT09PV0FBQYkhPn36dPXq1Utjx45VixYt9MILLygxMdF5e61atXTTTTepRo0aCg8PV3h4uGrVquW8fciQIRo4cKCioqL02muvKS8vT5s3bza+bgAAvAl5DXg3SjdQjcXFxSk/P1/ff/+9vvvuO7Vo0UIhISGKjY11vk8sLS1NzZo1U6NGjYodv2fPHnXr1s1lW0xMTJm/f/v27Z1f16lTRw6HQ8eOHav4ggAA8EHkNeDdarh7AADuExUVpYYNG2r16tU6ffq0YmNjJUkNGjRQZGSkNmzYoNWrV+uee+4x8v1r1qzpct1ms6moqMjI9wIAwFuR14B345VuoJr77YQraWlpLh890rNnT3311VfavHlziX+qJkmtWrXSpk2bXLb9/oQukhQQEKDCwsJKnxsAgOqEvAa8F6UbqObi4+O1bt06ZWRkOH9zLkmxsbGaPXu2Ll68WGqIv/DCC1q+fLmmTp2qffv26d1339Xy5ctd9mnSpIkOHDigjIwMnThxQgUFBUbXAwCALyKvAe9F6Qaqufj4eJ0/f15RUVEKCwtzbo+NjdXZs2edH1VSku7du+u//uu/NH36dHXo0EHffPONXn75ZZd9HnvsMfXq1Uvx8fEKCQnR//zP/xhdDwAAvoi8BryXzbIsy91DAAAAAADgi3ilGwAAAAAAQyjdAAAAAAAYQukGAAAAAMAQSjcAAAAAAIZQugEAAAAAMITSDQAAAACAIZRuAAAAAAAMoXQDAAAAAGAIpRsAAAAAAEMo3QAAAAAAGELpBgAAAADAEEo3AAAAAACG/D99c2PXRoeEdwAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Q. torch.Size([2, 3, 4]) 의 의미는?\n","\n","A. torch.Size([2, 3, 4])는 PyTorch 텐서의 형태(shape)를 나타내며, 3차원 텐서의 각 차원의 크기를 의미하며,\n","\n","각 차원에 대한 해석은 다음과 같이 할 수 있습니다.\n","\n","- 첫 번째 차원 (2): 텐서의 깊이 또는 채널 수를 나타냅니다.\n","    - (예: 2개의 이미지 또는 2개의 특징 맵)\n","\n","- 두 번째 차원 (3): 각 채널의 행 수를 나타냅니다.\n","    - 예: 각 이미지나 특징 맵의 높이\n","\n","- 세 번째 차원 (4): 각 행의 열 수를 나타냅니다.\n","    - 예: 각 이미지나 특징 맵의 너비\n","\n","- 실제 예시:\n","\n","    - 이미지 처리: 2개의 흑백 이미지, 각각 3x4 픽셀\n","    - 자연어 처리: 2개의 문장, 각 문장은 3개의 단어, 각 단어는 4차원 임베딩 벡터"],"metadata":{"id":"tOyJcxNCfrTb"}}]}